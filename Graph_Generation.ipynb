{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28d451a-234b-4b81-be9f-592a82d3d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ca9460-6042-425d-82ac-3f76829ef653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadeer/PycharmProjects/go/venv/lib/python3.8/site-packages/allennlp/tango/__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  warnings.warn(\n",
      "2021-11-13 20:30:42,945 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-11-13 20:30:43,428 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz is up-to-date\n",
      "2021-11-13 20:30:43,431 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz from cache at /home/hadeer/.allennlp/cache/0f6b052811b20b13280e609a96efe71ebc636b9c823a5c906ba24459e6e68af9.c1dab61d84cc7c3f7d6751c260040607cb7023a002778ba8f9b9d196b6539174\n",
      "2021-11-13 20:30:43,433 - INFO - allennlp.models.archival - extracting archive file /home/hadeer/.allennlp/cache/0f6b052811b20b13280e609a96efe71ebc636b9c823a5c906ba24459e6e68af9.c1dab61d84cc7c3f7d6751c260040607cb7023a002778ba8f9b9d196b6539174 to temp dir /tmp/tmpqaak9y04\n",
      "2021-11-13 20:30:51,304 - INFO - allennlp.common.params - dataset_reader.type = coref\n",
      "2021-11-13 20:30:51,305 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-11-13 20:30:51,306 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-13 20:30:51,306 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-13 20:30:51,306 - INFO - allennlp.common.params - dataset_reader.max_span_width = 30\n",
      "2021-11-13 20:30:51,307 - INFO - allennlp.common.params - dataset_reader.token_indexers.type = ref\n",
      "2021-11-13 20:30:51,310 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-11-13 20:30:51,310 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-11-13 20:30:51,311 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-11-13 20:30:51,311 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2021-11-13 20:30:51,311 - INFO - allennlp.common.params - type = SpanBERT/spanbert-large-cased\n",
      "2021-11-13 20:30:51,312 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2021-11-13 20:30:51,312 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2021-11-13 20:30:51,312 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2021-11-13 20:30:59,381 - INFO - allennlp.common.params - dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2021-11-13 20:30:59,382 - INFO - allennlp.common.params - dataset_reader.max_sentences = 110\n",
      "2021-11-13 20:30:59,382 - INFO - allennlp.common.params - dataset_reader.remove_singleton_clusters = False\n",
      "2021-11-13 20:30:59,383 - INFO - allennlp.common.params - validation_dataset_reader.type = coref\n",
      "2021-11-13 20:30:59,383 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\n",
      "2021-11-13 20:30:59,384 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\n",
      "2021-11-13 20:30:59,384 - INFO - allennlp.common.params - validation_dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-11-13 20:30:59,384 - INFO - allennlp.common.params - validation_dataset_reader.max_span_width = 30\n",
      "2021-11-13 20:30:59,384 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.type = ref\n",
      "2021-11-13 20:30:59,385 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-11-13 20:30:59,386 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.type = pretrained_transformer_mismatched\n",
      "2021-11-13 20:30:59,386 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-11-13 20:30:59,386 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2021-11-13 20:30:59,387 - INFO - allennlp.common.params - type = SpanBERT/spanbert-large-cased\n",
      "2021-11-13 20:30:59,387 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2021-11-13 20:30:59,387 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2021-11-13 20:30:59,388 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2021-11-13 20:30:59,390 - INFO - allennlp.common.params - validation_dataset_reader.wordpiece_modeling_tokenizer = None\n",
      "2021-11-13 20:30:59,391 - INFO - allennlp.common.params - validation_dataset_reader.max_sentences = None\n",
      "2021-11-13 20:30:59,391 - INFO - allennlp.common.params - validation_dataset_reader.remove_singleton_clusters = False\n",
      "2021-11-13 20:30:59,392 - INFO - allennlp.common.params - type = from_instances\n",
      "2021-11-13 20:30:59,392 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpqaak9y04/vocabulary.\n",
      "2021-11-13 20:30:59,393 - INFO - allennlp.common.params - model.type = coref\n",
      "2021-11-13 20:30:59,394 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2021-11-13 20:30:59,395 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2021-11-13 20:30:59,395 - INFO - allennlp.common.params - model.text_field_embedder.type = ref\n",
      "2021-11-13 20:30:59,396 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
      "2021-11-13 20:30:59,397 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.type = ref\n",
      "2021-11-13 20:30:59,399 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer_mismatched\n",
      "2021-11-13 20:30:59,399 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer_mismatched\n",
      "2021-11-13 20:30:59,400 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = SpanBERT/spanbert-large-cased\n",
      "2021-11-13 20:30:59,400 - INFO - allennlp.common.params - type = SpanBERT/spanbert-large-cased\n",
      "2021-11-13 20:30:59,400 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\n",
      "2021-11-13 20:30:59,401 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True\n",
      "2021-11-13 20:30:59,401 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True\n",
      "2021-11-13 20:30:59,402 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None\n",
      "2021-11-13 20:30:59,402 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None\n",
      "2021-11-13 20:30:59,402 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.load_weights = True\n",
      "2021-11-13 20:30:59,403 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None\n",
      "2021-11-13 20:30:59,403 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None\n",
      "2021-11-13 20:30:59,403 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None\n",
      "2021-11-13 20:30:59,404 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_token_mode = avg\n",
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2021-11-13 20:31:02,436 - INFO - allennlp.common.params - model.context_layer.type = pass_through\n",
      "2021-11-13 20:31:02,436 - INFO - allennlp.common.params - model.context_layer.type = pass_through\n",
      "2021-11-13 20:31:02,437 - INFO - allennlp.common.params - model.context_layer.input_dim = 1024\n",
      "2021-11-13 20:31:02,437 - INFO - allennlp.common.params - model.mention_feedforward.type = ref\n",
      "2021-11-13 20:31:02,438 - INFO - allennlp.common.params - model.mention_feedforward.input_dim = 3092\n",
      "2021-11-13 20:31:02,439 - INFO - allennlp.common.params - model.mention_feedforward.num_layers = 2\n",
      "2021-11-13 20:31:02,439 - INFO - allennlp.common.params - model.mention_feedforward.hidden_dims = 1500\n",
      "2021-11-13 20:31:02,440 - INFO - allennlp.common.params - model.mention_feedforward.activations = relu\n",
      "2021-11-13 20:31:02,440 - INFO - allennlp.common.params - type = relu\n",
      "2021-11-13 20:31:02,440 - INFO - allennlp.common.params - type = relu\n",
      "2021-11-13 20:31:02,441 - INFO - allennlp.common.params - type = relu\n",
      "2021-11-13 20:31:02,441 - INFO - allennlp.common.params - model.mention_feedforward.dropout = 0.3\n",
      "2021-11-13 20:31:02,478 - INFO - allennlp.common.params - model.antecedent_feedforward.type = ref\n",
      "2021-11-13 20:31:02,481 - INFO - allennlp.common.params - model.antecedent_feedforward.input_dim = 9296\n",
      "2021-11-13 20:31:02,482 - INFO - allennlp.common.params - model.antecedent_feedforward.num_layers = 2\n",
      "2021-11-13 20:31:02,482 - INFO - allennlp.common.params - model.antecedent_feedforward.hidden_dims = 1500\n",
      "2021-11-13 20:31:02,483 - INFO - allennlp.common.params - model.antecedent_feedforward.activations = relu\n",
      "2021-11-13 20:31:02,483 - INFO - allennlp.common.params - type = relu\n",
      "2021-11-13 20:31:02,484 - INFO - allennlp.common.params - type = relu\n",
      "2021-11-13 20:31:02,484 - INFO - allennlp.common.params - type = relu\n",
      "2021-11-13 20:31:02,485 - INFO - allennlp.common.params - model.antecedent_feedforward.dropout = 0.3\n",
      "2021-11-13 20:31:02,571 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2021-11-13 20:31:02,572 - INFO - allennlp.common.params - model.max_span_width = 30\n",
      "2021-11-13 20:31:02,572 - INFO - allennlp.common.params - model.spans_per_word = 0.4\n",
      "2021-11-13 20:31:02,573 - INFO - allennlp.common.params - model.max_antecedents = 50\n",
      "2021-11-13 20:31:02,573 - INFO - allennlp.common.params - model.coarse_to_fine = True\n",
      "2021-11-13 20:31:02,574 - INFO - allennlp.common.params - model.inference_order = 2\n",
      "2021-11-13 20:31:02,574 - INFO - allennlp.common.params - model.lexical_dropout = 0.2\n",
      "2021-11-13 20:31:02,574 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f9b38e69340>\n",
      "2021-11-13 20:31:02,625 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2021-11-13 20:31:02,626 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2021-11-13 20:31:02,626 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.bias\n",
      "2021-11-13 20:31:02,626 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.0.weight\n",
      "2021-11-13 20:31:02,627 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.bias\n",
      "2021-11-13 20:31:02,627 - INFO - allennlp.nn.initializers -    _antecedent_feedforward._module._linear_layers.1.weight\n",
      "2021-11-13 20:31:02,627 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.bias\n",
      "2021-11-13 20:31:02,628 - INFO - allennlp.nn.initializers -    _antecedent_scorer._module.weight\n",
      "2021-11-13 20:31:02,628 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.bias\n",
      "2021-11-13 20:31:02,628 - INFO - allennlp.nn.initializers -    _attentive_span_extractor._global_attention._module.weight\n",
      "2021-11-13 20:31:02,628 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.bias\n",
      "2021-11-13 20:31:02,628 - INFO - allennlp.nn.initializers -    _coarse2fine_scorer.weight\n",
      "2021-11-13 20:31:02,629 - INFO - allennlp.nn.initializers -    _distance_embedding.weight\n",
      "2021-11-13 20:31:02,629 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
      "2021-11-13 20:31:02,629 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.bias\n",
      "2021-11-13 20:31:02,629 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.0.weight\n",
      "2021-11-13 20:31:02,630 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.bias\n",
      "2021-11-13 20:31:02,630 - INFO - allennlp.nn.initializers -    _mention_feedforward._module._linear_layers.1.weight\n",
      "2021-11-13 20:31:02,630 - INFO - allennlp.nn.initializers -    _mention_scorer._module.bias\n",
      "2021-11-13 20:31:02,630 - INFO - allennlp.nn.initializers -    _mention_scorer._module.weight\n",
      "2021-11-13 20:31:02,630 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.bias\n",
      "2021-11-13 20:31:02,631 - INFO - allennlp.nn.initializers -    _span_updating_gated_sum._gate.weight\n",
      "2021-11-13 20:31:02,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2021-11-13 20:31:02,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2021-11-13 20:31:02,631 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2021-11-13 20:31:02,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2021-11-13 20:31:02,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2021-11-13 20:31:02,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,632 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-11-13 20:31:02,633 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-11-13 20:31:02,634 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-11-13 20:31:02,634 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-11-13 20:31:02,634 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-11-13 20:31:02,634 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-11-13 20:31:02,635 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,635 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,635 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,636 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2021-11-13 20:31:02,638 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2021-11-13 20:31:02,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,639 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-11-13 20:31:02,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-11-13 20:31:02,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-11-13 20:31:02,640 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-11-13 20:31:02,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-11-13 20:31:02,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-11-13 20:31:02,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,641 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2021-11-13 20:31:02,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2021-11-13 20:31:02,642 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,643 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-11-13 20:31:02,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-11-13 20:31:02,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-11-13 20:31:02,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-11-13 20:31:02,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-11-13 20:31:02,644 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-11-13 20:31:02,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,645 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2021-11-13 20:31:02,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2021-11-13 20:31:02,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,646 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-11-13 20:31:02,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-11-13 20:31:02,647 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-11-13 20:31:02,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-11-13 20:31:02,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-11-13 20:31:02,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-11-13 20:31:02,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,648 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2021-11-13 20:31:02,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2021-11-13 20:31:02,649 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,650 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.bias\n",
      "2021-11-13 20:31:02,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.key.weight\n",
      "2021-11-13 20:31:02,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.bias\n",
      "2021-11-13 20:31:02,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.query.weight\n",
      "2021-11-13 20:31:02,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.bias\n",
      "2021-11-13 20:31:02,651 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.attention.self.value.weight\n",
      "2021-11-13 20:31:02,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,652 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.bias\n",
      "2021-11-13 20:31:02,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.12.output.dense.weight\n",
      "2021-11-13 20:31:02,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,653 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.bias\n",
      "2021-11-13 20:31:02,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.key.weight\n",
      "2021-11-13 20:31:02,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.bias\n",
      "2021-11-13 20:31:02,654 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.query.weight\n",
      "2021-11-13 20:31:02,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.bias\n",
      "2021-11-13 20:31:02,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.attention.self.value.weight\n",
      "2021-11-13 20:31:02,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,655 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.bias\n",
      "2021-11-13 20:31:02,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.13.output.dense.weight\n",
      "2021-11-13 20:31:02,656 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,657 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.bias\n",
      "2021-11-13 20:31:02,658 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.key.weight\n",
      "2021-11-13 20:31:02,658 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.bias\n",
      "2021-11-13 20:31:02,658 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.query.weight\n",
      "2021-11-13 20:31:02,659 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.bias\n",
      "2021-11-13 20:31:02,659 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.attention.self.value.weight\n",
      "2021-11-13 20:31:02,659 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,660 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,660 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,660 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,660 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.bias\n",
      "2021-11-13 20:31:02,661 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.14.output.dense.weight\n",
      "2021-11-13 20:31:02,661 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,661 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.bias\n",
      "2021-11-13 20:31:02,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.key.weight\n",
      "2021-11-13 20:31:02,662 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.bias\n",
      "2021-11-13 20:31:02,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.query.weight\n",
      "2021-11-13 20:31:02,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.bias\n",
      "2021-11-13 20:31:02,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.attention.self.value.weight\n",
      "2021-11-13 20:31:02,663 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,664 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,664 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,664 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,664 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.bias\n",
      "2021-11-13 20:31:02,664 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.15.output.dense.weight\n",
      "2021-11-13 20:31:02,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,665 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.bias\n",
      "2021-11-13 20:31:02,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.key.weight\n",
      "2021-11-13 20:31:02,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.bias\n",
      "2021-11-13 20:31:02,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.query.weight\n",
      "2021-11-13 20:31:02,666 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.bias\n",
      "2021-11-13 20:31:02,667 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.attention.self.value.weight\n",
      "2021-11-13 20:31:02,667 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,667 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,667 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,668 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,668 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.bias\n",
      "2021-11-13 20:31:02,677 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.16.output.dense.weight\n",
      "2021-11-13 20:31:02,678 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,678 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,679 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,679 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,680 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.bias\n",
      "2021-11-13 20:31:02,680 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.key.weight\n",
      "2021-11-13 20:31:02,681 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.bias\n",
      "2021-11-13 20:31:02,681 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.query.weight\n",
      "2021-11-13 20:31:02,681 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.bias\n",
      "2021-11-13 20:31:02,681 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.attention.self.value.weight\n",
      "2021-11-13 20:31:02,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,682 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.bias\n",
      "2021-11-13 20:31:02,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.17.output.dense.weight\n",
      "2021-11-13 20:31:02,683 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,684 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,684 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,685 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,685 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.bias\n",
      "2021-11-13 20:31:02,686 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.key.weight\n",
      "2021-11-13 20:31:02,686 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.bias\n",
      "2021-11-13 20:31:02,686 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.query.weight\n",
      "2021-11-13 20:31:02,687 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.bias\n",
      "2021-11-13 20:31:02,687 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.attention.self.value.weight\n",
      "2021-11-13 20:31:02,688 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,688 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,688 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.bias\n",
      "2021-11-13 20:31:02,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.18.output.dense.weight\n",
      "2021-11-13 20:31:02,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,689 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,690 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,690 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,690 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.bias\n",
      "2021-11-13 20:31:02,690 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.key.weight\n",
      "2021-11-13 20:31:02,691 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.bias\n",
      "2021-11-13 20:31:02,692 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.query.weight\n",
      "2021-11-13 20:31:02,693 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.bias\n",
      "2021-11-13 20:31:02,693 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.attention.self.value.weight\n",
      "2021-11-13 20:31:02,693 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,694 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,694 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,694 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,694 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.bias\n",
      "2021-11-13 20:31:02,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.19.output.dense.weight\n",
      "2021-11-13 20:31:02,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,695 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,696 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,696 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-11-13 20:31:02,696 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-11-13 20:31:02,696 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-11-13 20:31:02,696 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-11-13 20:31:02,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-11-13 20:31:02,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-11-13 20:31:02,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,697 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2021-11-13 20:31:02,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2021-11-13 20:31:02,698 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,699 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,699 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,699 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,699 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.bias\n",
      "2021-11-13 20:31:02,699 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.key.weight\n",
      "2021-11-13 20:31:02,700 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.bias\n",
      "2021-11-13 20:31:02,702 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.query.weight\n",
      "2021-11-13 20:31:02,702 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.bias\n",
      "2021-11-13 20:31:02,702 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.attention.self.value.weight\n",
      "2021-11-13 20:31:02,702 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,702 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.bias\n",
      "2021-11-13 20:31:02,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.20.output.dense.weight\n",
      "2021-11-13 20:31:02,703 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,704 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,704 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,704 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,704 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.bias\n",
      "2021-11-13 20:31:02,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.key.weight\n",
      "2021-11-13 20:31:02,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.bias\n",
      "2021-11-13 20:31:02,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.query.weight\n",
      "2021-11-13 20:31:02,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.bias\n",
      "2021-11-13 20:31:02,705 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.attention.self.value.weight\n",
      "2021-11-13 20:31:02,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,706 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.bias\n",
      "2021-11-13 20:31:02,707 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.21.output.dense.weight\n",
      "2021-11-13 20:31:02,707 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,707 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,707 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.bias\n",
      "2021-11-13 20:31:02,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.key.weight\n",
      "2021-11-13 20:31:02,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.bias\n",
      "2021-11-13 20:31:02,708 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.query.weight\n",
      "2021-11-13 20:31:02,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.bias\n",
      "2021-11-13 20:31:02,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.attention.self.value.weight\n",
      "2021-11-13 20:31:02,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,709 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.bias\n",
      "2021-11-13 20:31:02,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.22.output.dense.weight\n",
      "2021-11-13 20:31:02,710 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,711 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.bias\n",
      "2021-11-13 20:31:02,714 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.key.weight\n",
      "2021-11-13 20:31:02,714 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.bias\n",
      "2021-11-13 20:31:02,714 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.query.weight\n",
      "2021-11-13 20:31:02,715 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.bias\n",
      "2021-11-13 20:31:02,715 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.attention.self.value.weight\n",
      "2021-11-13 20:31:02,715 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,715 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,716 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,716 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,716 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.bias\n",
      "2021-11-13 20:31:02,716 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.23.output.dense.weight\n",
      "2021-11-13 20:31:02,716 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,717 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,717 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,718 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,718 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-11-13 20:31:02,718 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-11-13 20:31:02,718 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-11-13 20:31:02,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-11-13 20:31:02,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-11-13 20:31:02,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-11-13 20:31:02,719 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2021-11-13 20:31:02,720 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2021-11-13 20:31:02,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,721 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-11-13 20:31:02,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-11-13 20:31:02,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-11-13 20:31:02,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-11-13 20:31:02,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-11-13 20:31:02,722 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-11-13 20:31:02,723 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,723 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,723 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,723 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2021-11-13 20:31:02,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2021-11-13 20:31:02,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,724 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,725 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,725 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-11-13 20:31:02,725 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-11-13 20:31:02,725 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-11-13 20:31:02,725 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-11-13 20:31:02,726 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-11-13 20:31:02,726 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-11-13 20:31:02,728 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,728 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,729 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,729 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,729 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2021-11-13 20:31:02,729 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2021-11-13 20:31:02,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,730 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-11-13 20:31:02,731 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-11-13 20:31:02,731 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-11-13 20:31:02,731 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-11-13 20:31:02,731 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-11-13 20:31:02,731 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-11-13 20:31:02,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,732 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2021-11-13 20:31:02,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2021-11-13 20:31:02,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,733 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-11-13 20:31:02,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-11-13 20:31:02,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-11-13 20:31:02,734 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-11-13 20:31:02,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-11-13 20:31:02,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-11-13 20:31:02,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,735 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2021-11-13 20:31:02,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2021-11-13 20:31:02,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,736 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-11-13 20:31:02,737 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-11-13 20:31:02,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-11-13 20:31:02,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-11-13 20:31:02,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-11-13 20:31:02,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-11-13 20:31:02,738 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,739 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2021-11-13 20:31:02,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2021-11-13 20:31:02,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-11-13 20:31:02,740 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-11-13 20:31:02,741 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-11-13 20:31:02,741 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-11-13 20:31:02,741 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-11-13 20:31:02,741 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-11-13 20:31:02,741 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-11-13 20:31:02,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-11-13 20:31:02,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-11-13 20:31:02,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-11-13 20:31:02,742 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-11-13 20:31:02,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-11-13 20:31:02,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2021-11-13 20:31:02,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2021-11-13 20:31:02,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2021-11-13 20:31:02,743 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2021-11-13 20:31:02,750 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2021-11-13 20:31:02,751 - INFO - allennlp.modules.token_embedders.embedding - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2021-11-13 20:31:03,451 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpqaak9y04\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "model_url = 'https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz'\n",
    "predictor = Predictor.from_path(model_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb431358-1328-47a2-a663-239b1532bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root_of_sentence(doc):\n",
    "    root_token = None\n",
    "    for token in doc:\n",
    "        if (token.dep_ == \"ROOT\"):\n",
    "            root_token = token\n",
    "    return root_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4743ad42-a4b2-44b4-9af0-4bb6753d14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_other_verbs(doc, root_token):\n",
    "    other_verbs = []\n",
    "    for token in doc:\n",
    "        ancestors = list(token.ancestors)\n",
    "        if (token.pos_ == \"VERB\" and len(ancestors) == 1\\\n",
    "            and ancestors[0] == root_token):\n",
    "            other_verbs.append(token)\n",
    "    return other_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52054378-e25f-4a0d-8599-ef2b69c79f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clause_token_span_for_verb(verb, doc, all_verbs):\n",
    "    first_token_index = len(doc)\n",
    "    last_token_index = 0\n",
    "    this_verb_children = list(verb.children)\n",
    "    for child in this_verb_children:\n",
    "        if (child not in all_verbs):\n",
    "            if (child.i < first_token_index):\n",
    "                first_token_index = child.i\n",
    "            if (child.i > last_token_index):\n",
    "                last_token_index = child.i\n",
    "    return(first_token_index, last_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482889cb-abf4-42d0-bd6b-4f8e641e7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_patterns = [[{\"POS\":\"AUX\"}, {\"POS\":\"VERB\"}, \n",
    "                  {\"POS\":\"ADP\"}], \n",
    "                 [{\"POS\":\"AUX\"}],\n",
    "                [{'POS': 'VERB', 'OP': '?'},\n",
    "           {'POS': 'ADV', 'OP': '*'},\n",
    "           {'POS': 'VERB', 'OP': '+'}]]\n",
    "\n",
    "# pattern = [{'POS': 'VERB', 'OP': '?'},\n",
    "#            {'POS': 'ADV', 'OP': '*'},\n",
    "#            {'POS': 'VERB', 'OP': '+'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80fe862-eb1c-40c6-8b51-651f42bd6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_root(verb_phrase, root):\n",
    "    vp_start = verb_phrase.start\n",
    "    vp_end = verb_phrase.end\n",
    "    if (root.i >= vp_start and root.i <= vp_end):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02995f70-42fe-43f9-8e2e-c8a4e38015fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_phrases(doc):\n",
    "    root = find_root_of_sentence(doc)\n",
    "    verb_phrases = textacy.extract.matches.token_matches(doc, verb_patterns)\n",
    "                                           # verb_patterns)\n",
    "    # print(verb_phrases)spacy.matcher.Matcher.\n",
    "    new_vps = []\n",
    "    for verb_phrase in verb_phrases:\n",
    "        if (contains_root(verb_phrase, root)):\n",
    "            new_vps.append(verb_phrase)\n",
    "    return new_vps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df20b20-38ee-4da8-8480-81a5baddafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longer_verb_phrase(verb_phrases):\n",
    "    longest_length = 0\n",
    "    longest_verb_phrase = None\n",
    "    for verb_phrase in verb_phrases:\n",
    "        if len(verb_phrase) > longest_length:\n",
    "            longest_verb_phrase = verb_phrase\n",
    "    return longest_verb_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52aa215a-1891-42a3-b1ea-60511317e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_noun_phrase(verb_phrase, noun_phrases, side):\n",
    "    for noun_phrase in noun_phrases:\n",
    "        if (side == \"left\" and \\\n",
    "            noun_phrase.start < verb_phrase.start):\n",
    "            return noun_phrase\n",
    "        elif (side == \"right\" and \\\n",
    "              noun_phrase.start > verb_phrase.start):\n",
    "            return noun_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5c56ee-9fcd-4a12-8aee-df5b417e77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triplet(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    # print(doc)\n",
    "    verb_phrases = get_verb_phrases(doc)\n",
    "    noun_phrases = doc.noun_chunks\n",
    "    verb_phrase = None\n",
    "    if (len(verb_phrases) > 1):\n",
    "        verb_phrase = \\\n",
    "        longer_verb_phrase(list(verb_phrases))\n",
    "    else:\n",
    "        # print(verb_phrase)\n",
    "        verb_phrase = verb_phrases[0]\n",
    "    left_noun_phrase = find_noun_phrase(verb_phrase, \n",
    "                                        noun_phrases, \n",
    "                                        \"left\")\n",
    "    right_noun_phrase = find_noun_phrase(verb_phrase, \n",
    "                                         noun_phrases, \n",
    "                                         \"right\")\n",
    "    return (left_noun_phrase, verb_phrase, \n",
    "            right_noun_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c351fc2e-6d7a-47fa-9bb5-b51d6afd233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(text):\n",
    "    text = re.sub(r'\\n+', '.', text)  # replace multiple newlines with period\n",
    "    text = re.sub(r'\\[\\d+\\]', ' ', text)  # remove reference numbers\n",
    "    text = predictor.coref_resolved(text)\n",
    "    text=nlp(text)\n",
    "    sens= [str(i).lstrip() for i in list(text.sents)]\n",
    "    ent_pairs=[]\n",
    "    for sent in sens:\n",
    "        try:\n",
    "            pair= list(find_triplet(sent.lower()))\n",
    "            if None in pair:\n",
    "                pass\n",
    "            else:\n",
    "                ent_pairs.append(pair)\n",
    "            \n",
    "            \n",
    "                # print( list(textacy.extract.triples.subject_verb_object_triples(nlp(sent))))\n",
    "        except (IndexError, AttributeError) as e:\n",
    "            pass\n",
    "    pairs = pd.DataFrame(ent_pairs, columns=['subject', 'relation', 'object'])\n",
    "    pairs['subject'] = pairs['subject'].astype(str)\n",
    "    pairs['relation'] = pairs['relation'].astype(str)\n",
    "    pairs['object'] = pairs['object'].astype(str)\n",
    "    return(pairs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3082a13-872a-414f-9eb3-3b02aab27d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_kg(pairs):\n",
    "    k_graph = nx.from_pandas_edgelist(pairs, 'subject','object',\n",
    "            create_using=nx.MultiDiGraph())\n",
    "    node_deg = nx.degree(k_graph)\n",
    "    layout = nx.spring_layout(k_graph, k=0.15, iterations=20)\n",
    "    plt.figure(num=None, figsize=(120, 90), dpi=80)\n",
    "    nx.draw_networkx(\n",
    "        k_graph,\n",
    "        node_size=[int(deg[1]) * 500 for deg in node_deg],\n",
    "        arrowsize=20,\n",
    "        linewidths=1.5,\n",
    "        pos=layout,\n",
    "        edge_color='red',\n",
    "        edgecolors='black',\n",
    "        node_color='white',\n",
    "        )\n",
    "    labels = dict(zip(list(zip(pairs.subject, pairs.object)),\n",
    "                  pairs['relation'].tolist()))\n",
    "    nx.draw_networkx_edge_labels(k_graph, pos=layout, edge_labels=labels,\n",
    "                                 font_color='red')\n",
    "    # print(nx.to_dict_of_dicts(k_graph))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2052c822-cd4d-4c74-9c71-d3d8aa58b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(pairs):\n",
    "    \n",
    "    attr_graph = nx.MultiDiGraph()\n",
    "    for index, row in pairs.iterrows():\n",
    "        attr_graph.add_nodes_from([\n",
    "        (row['subject'], {\"type\": \"subject\"}),\n",
    "        (row['object'], {\"type\": \"object\"}),\n",
    "        ])\n",
    "        attr_graph.add_edges_from([(row['subject'], row['object'], {\"type\": \"verb\",\"label\":row['relation']})])\n",
    "    return attr_graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca988aeb-50e0-4d26-a7cd-9afef3cdb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as pvnet\n",
    "\n",
    "def plot_g_pyviz(G, name='out.html', height='300px', width='500px'):\n",
    "    g = G.copy() # some attributes added to nodes\n",
    "    net = pvnet.Network(notebook=True, directed=True, height=height, width=width)\n",
    "    opts = '''\n",
    "        var options = {\n",
    "          \"physics\": {\n",
    "            \"forceAtlas2Based\": {\n",
    "              \"gravitationalConstant\": -100,\n",
    "              \"centralGravity\": 0.11,\n",
    "              \"springLength\": 100,\n",
    "              \"springConstant\": 0.09,\n",
    "              \"avoidOverlap\": 1\n",
    "            },\n",
    "            \"minVelocity\": 0.75,\n",
    "            \"solver\": \"forceAtlas2Based\",\n",
    "            \"timestep\": 0.22\n",
    "          }\n",
    "        }\n",
    "    '''\n",
    "\n",
    "    net.set_options(opts)\n",
    "    # uncomment this to play with layout\n",
    "    # net.show_buttons(filter_=['physics'])\n",
    "    net.from_nx(g)\n",
    "    return net.show(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "890cc813-d9fc-4de7-b0a3-80183ddb7123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"300px\"\n",
       "            src=\"out.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9b32e634c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_g_pyviz(get_graph(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c1584-e32f-4599-a659-369e4df066ae",
   "metadata": {},
   "source": [
    "This set of functions will extract one word only as subject or object instead of phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec85d4ad-d409-40d1-99e8-c7b30e0c35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sen_structure(doc):\n",
    "    structure = {}\n",
    "    for token in nlp(doc):\n",
    "        ancestors = [t.text for t in token.ancestors]\n",
    "        children = [t.text for t in token.children]\n",
    "        structure[token.i] = {\"text\" : token.text,\"dep\":token.dep_}\n",
    "                              # \"children\":children,\"ancestors\":ancestors}\n",
    "        # print(token.text, \"\\t\", token.i, \"\\t\", \n",
    "        #       token.pos_, \"\\t\", token.dep_, \"\\t\", \n",
    "        #       ancestors, \"\\t\", children)\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57b7be52-bce7-401a-bd4b-e9de2ed2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_pairs(text):\n",
    "    Sentences = [str(i).lstrip()for i in list(nlp(predictor.coref_resolved(text)).sents)]\n",
    "    pairs=[]\n",
    "    for i in Sentences:\n",
    "        # print(i)\n",
    "        dic = get_sen_structure(i.lower())\n",
    "        # print (dic)\n",
    "        for key in dic :\n",
    "            if (dic[key]['dep']) == 'ROOT':\n",
    "                verb  = dic[key]['text']\n",
    "            elif (dic[key]['dep']) == 'nsubj' or  (dic[key]['dep']) == 'csubj':\n",
    "                subject = dic[key]['text']\n",
    "            elif (dic[key]['dep']) == 'dobj' or  (dic[key]['dep']) == 'pobj' or  (dic[key]['dep']) == 'attr':\n",
    "                obj = dic[key]['text']\n",
    "            else:\n",
    "                pass\n",
    "        if \"\" in [subject,verb,obj]:\n",
    "            pass\n",
    "        else:\n",
    "            pairs.append([subject,verb,obj]) \n",
    "            verb,subject,obj= \"\",\"\",\"\"\n",
    "    allpairs = pd.DataFrame(pairs, columns=['subject', 'relation', 'object'])\n",
    "    return allpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccd327c3-3b1c-4600-9847-39e8b9b3ae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"300px\"\n",
       "            src=\"out.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9c60794040>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_g_pyviz(get_graph(get_single_pairs(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87ef97d3-1d82-44f1-9321-0483a6426278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = get_graph(get_single_pairs(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72067d88-9dfe-4f39-8237-ce3b843a27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_dict(graph):\n",
    "    return nx.to_dict_of_dicts(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ead18b6-432b-46b6-91b8-c0c5b3e319ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1271ef3-ebeb-4f2a-9999-6fdb0ef31a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_pickle(graph):\n",
    "    return nx.write_gpickle(graph,\"graph.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ca4a20b-e984-49ef-b9aa-b8be0123406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_pickle(path):\n",
    "    return nx.read_gpickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "364353f9-7354-4dff-a60b-979254107731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # object and subject constants\n",
    "# OBJECT_DEPS = {\"dobj\", \"dative\", \"attr\", \"oprd\"}\n",
    "# SUBJECT_DEPS = {\"nsubj\", \"nsubjpass\", \"csubj\", \"agent\", \"expl\"}\n",
    "# # tags that define wether the word is wh-\n",
    "# WH_WORDS = {\"WP\", \"WP$\", \"WRB\"}\n",
    "\n",
    "# # extract the subject, object and verb from the input\n",
    "# def extract_svo(doc):\n",
    "#     doc=nlp(doc)\n",
    "#     sub = []\n",
    "#     at = []\n",
    "#     ve = []\n",
    "#     for token in doc:\n",
    "#         # is this a verb?\n",
    "#         if token.dep_ == \"ROOT\" :\n",
    "#             ve.append(token.text)\n",
    "#             # print(token.text)\n",
    "#         # is this the object?\n",
    "#         if token.dep_ in OBJECT_DEPS or token.head.dep_ in OBJECT_DEPS:\n",
    "#             at.append(token.text)\n",
    "#         # is this the subject?\n",
    "#         if token.dep_ in SUBJECT_DEPS or token.head.dep_ in SUBJECT_DEPS:\n",
    "#             sub.append(token.text)\n",
    "#     return \" \".join(sub).strip().lower(), \" \".join(ve).strip().lower(), \" \".join(at).strip().lower()\n",
    "\n",
    "# def get_pairs_3rd(text):\n",
    "#     Sentences = [str(i).lstrip()for i in list(nlp(predictor.coref_resolved(text)).sents)]\n",
    "#     pairs=[]\n",
    "#     for i in Sentences:\n",
    "#         pairs.append(list(extract_svo(i.lower()))) \n",
    "#     allpairs = pd.DataFrame(pairs, columns=['subject', 'relation', 'object'])\n",
    "#     return allpairs\n",
    "\n",
    "# get_pairs_3rd(\"Traveling to have a business meeting takes the fun out of the trip\")\n",
    "#     # enron.text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ad67db1-7314-41a7-97d9-6bd95bb1bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=\"Elizabeth, I need to update several of our faculty and teaching staff on the changes in the English department’s process for assigning teaching schedules to Graduate Teaching Assistants. As you know, the old process gave preference to more senior TAs, which led to numerous complaints of unfairness and an overall lack of clarity. Starting next semester, the English department will transition to a new rolling system that divides TAs into four groups alphabetically and ensures each group will be given first preference of teaching times once every two academic years. This change will go into effect starting January 5, 2015. In your message I would like you to outline the new process and explain the reasons why we need to make this change. Please provide contact information for the assistant department head in case anyone needs further information. Oh, and this information will also need to be copied to the appropriate associate dean. I appreciate your help with this.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0c91042-52de-4a2d-88c1-4053e9f0a79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>need</td>\n",
       "      <td>our faculty and teaching staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elizabeth</td>\n",
       "      <td>gave</td>\n",
       "      <td>preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the english department</td>\n",
       "      <td>transition</td>\n",
       "      <td>a new rolling system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transition</td>\n",
       "      <td>go</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elizabeth's message</td>\n",
       "      <td>given</td>\n",
       "      <td>first preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>contact information</td>\n",
       "      <td>need</td>\n",
       "      <td>the appropriate associate dean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i</td>\n",
       "      <td>appreciate</td>\n",
       "      <td>elizabeth's help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  subject    relation                          object\n",
       "0                       i        need  our faculty and teaching staff\n",
       "1               elizabeth        gave                      preference\n",
       "2  the english department  transition            a new rolling system\n",
       "3              transition          go                          effect\n",
       "4     elizabeth's message       given                first preference\n",
       "5     contact information        need  the appropriate associate dean\n",
       "6                       i  appreciate                elizabeth's help"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_1= get_pairs(sample)\n",
    "pairs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "042221eb-0200-4fff-8296-a4ae5f86a74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>need</td>\n",
       "      <td>assistants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which</td>\n",
       "      <td>gave</td>\n",
       "      <td>clarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>transition</td>\n",
       "      <td>years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transition</td>\n",
       "      <td>go</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we</td>\n",
       "      <td>given</td>\n",
       "      <td>transition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anyone</td>\n",
       "      <td>provide</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>information</td>\n",
       "      <td>need</td>\n",
       "      <td>dean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i</td>\n",
       "      <td>appreciate</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject    relation       object\n",
       "0            i        need   assistants\n",
       "1        which        gave      clarity\n",
       "2         that  transition        years\n",
       "3   transition          go       effect\n",
       "4           we       given   transition\n",
       "5       anyone     provide  information\n",
       "6  information        need         dean\n",
       "7            i  appreciate         this"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_2 = get_single_pairs(sample)\n",
    "pairs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "205f2c75-ab70-4846-b702-2faf97a87760",
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = get_graph(pairs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e67c2db1-d3bd-4166-acab-dea76fd502d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"300px\"\n",
       "            src=\"out.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9b32f44940>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Draw the graph\n",
    "plot_g_pyviz(Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02d06639-f707-43f8-813d-c43fb2426d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': {'our faculty and teaching staff': {0: {'type': 'verb',\n",
       "    'label': 'need'}},\n",
       "  \"elizabeth's help\": {0: {'type': 'verb', 'label': 'appreciate'}}},\n",
       " 'our faculty and teaching staff': {},\n",
       " 'elizabeth': {'preference': {0: {'type': 'verb', 'label': 'gave'}}},\n",
       " 'preference': {},\n",
       " 'the english department': {'a new rolling system': {0: {'type': 'verb',\n",
       "    'label': 'transition'}}},\n",
       " 'a new rolling system': {},\n",
       " 'transition': {'effect': {0: {'type': 'verb', 'label': 'go'}}},\n",
       " 'effect': {},\n",
       " \"elizabeth's message\": {'first preference': {0: {'type': 'verb',\n",
       "    'label': 'given'}}},\n",
       " 'first preference': {},\n",
       " 'contact information': {'the appropriate associate dean': {0: {'type': 'verb',\n",
       "    'label': 'need'}}},\n",
       " 'the appropriate associate dean': {},\n",
       " \"elizabeth's help\": {}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the graph dict\n",
    "get_graph_dict(Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3725ad4-724c-4947-8b07-ef689bdf3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the graph dict\n",
    "save_graph_pickle(Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e28ce333-b095-432c-9d49-a1b7c2849682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graph\n",
    "G = load_graph_pickle(path='graph.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa5c88-2bbe-4a19-bffc-7a523749fe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b9241-7141-4f70-8b2f-47410d264cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8a6f8-9284-4686-bd95-f0a2c003a0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c55569-1cd3-4b47-9e72-5d234f950eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d96f8-34af-48f3-9aa3-1cdebd5cb370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd474ce0-5b53-48ea-a31a-3773a5836798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84828604-f115-403f-87d2-4d3384f8619c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5056f-3641-4149-a40a-680165eb77cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5fe7c-282d-4ab2-8e97-b94c3fb9d00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed2c08-d28c-4a59-adae-cacf73d798f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dbbe5-6f98-4d49-ac97-7cb0aafedcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5e851-b0c4-4fd5-9763-597527331e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d69af5-afb0-4734-aeb3-13675305128a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce309862-3c93-4287-80c4-dcbc9a08a164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c008302-1b28-47a6-8e8f-9482be36239e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df461feb-3021-4165-8d28-4341d1fa8a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef232d-7000-47b4-afe0-aefad2ff68d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
